{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW #1\n",
    "Student name: Olha Tanyuk\n",
    "\n",
    "1.\tInstall Python (if you don’t have it already), and install NLTK.  \n",
    "\n",
    "2.\tFollow the instructions in chapter 1 of Bird-Klein for implementing a “lexical diversity” scoring routine.\n",
    "\n",
    "3.\tGo to http://www.gutenberg.org/wiki/Children%27s_Instructional_Books_(Bookshelf), and obtain three texts (of different grade levels) from the “Graded Readers” section. Report the lexical diversity score of each. Explain whether the result was surprising.\n",
    "\n",
    "4.\tAlso compare the vocabulary size of the same three texts. Explain whether the result was surprising.  \n",
    "\n",
    "5.\tWrite a paragraph arguing whether vocabulary size and lexical diversity in combination could be a better measure of text difficulty (or reading level) than either measure is by itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers:\n",
    "### 1. Python was installed.\n",
    "### 2. Getting Started with NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Sense and Sensibility by Jane Austen 1811>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we look up the word 'monstrous' in Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we search Sense and Sensibility for the word affection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 79 matches:\n",
      ", however , and , as a mark of his affection for the three girls , he left them\n",
      "t . It was very well known that no affection was ever supposed to exist between\n",
      "deration of politeness or maternal affection on the side of the former , the tw\n",
      "d the suspicion -- the hope of his affection for me may warrant , without impru\n",
      "hich forbade the indulgence of his affection . She knew that his mother neither\n",
      "rd she gave one with still greater affection . Though her late conversation wit\n",
      " can never hope to feel or inspire affection again , and if her home be uncomfo\n",
      "m of the sense , elegance , mutual affection , and domestic comfort of the fami\n",
      ", and which recommended him to her affection beyond every thing else . His soci\n",
      "ween the parties might forward the affection of Mr . Willoughby , an equally st\n",
      " the most pointed assurance of her affection . Elinor could not be surprised at\n",
      "he natural consequence of a strong affection in a young and ardent mind . This \n",
      " opinion . But by an appeal to her affection for her mother , by representing t\n",
      " every alteration of a place which affection had established as perfect with hi\n",
      "e will always have one claim of my affection , which no other can possibly shar\n",
      "f the evening declared at once his affection and happiness . \" Shall we see you\n",
      "ause he took leave of us with less affection than his usual behaviour has shewn\n",
      "ness .\" \" I want no proof of their affection ,\" said Elinor ; \" but of their en\n",
      "onths , without telling her of his affection ;-- that they should part without \n",
      "ould be the natural result of your affection for her . She used to be all unres\n",
      "distinguished Elinor by no mark of affection . Marianne saw and listened with i\n",
      "th no inclination for expense , no affection for strangers , no profession , an\n",
      "till distinguished her by the same affection which once she had felt no doubt o\n",
      "al of her confidence in Edward ' s affection , to the remembrance of every mark\n",
      " was made ? Had he never owned his affection to yourself ?\" \" Oh , no ; but if \n"
     ]
    }
   ],
   "source": [
    "text2.concordance(\"affection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we search the book of Genesis to find out how long some people lived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 38 matches:\n",
      "ay when they were created . And Adam lived an hundred and thirty years , and be\n",
      "ughters : And all the days that Adam lived were nine hundred and thirty yea and\n",
      "nd thirty yea and he died . And Seth lived an hundred and five years , and bega\n",
      "ve years , and begat Enos : And Seth lived after he begat Enos eight hundred an\n",
      "welve years : and he died . And Enos lived ninety years , and begat Cainan : An\n",
      " years , and begat Cainan : And Enos lived after he begat Cainan eight hundred \n",
      "ive years : and he died . And Cainan lived seventy years and begat Mahalaleel :\n",
      "rs and begat Mahalaleel : And Cainan lived after he begat Mahalaleel eight hund\n",
      "years : and he died . And Mahalaleel lived sixty and five years , and begat Jar\n",
      "s , and begat Jared : And Mahalaleel lived after he begat Jared eight hundred a\n",
      "and five yea and he died . And Jared lived an hundred sixty and two years , and\n",
      "o years , and he begat Eno And Jared lived after he begat Enoch eight hundred y\n",
      " and two yea and he died . And Enoch lived sixty and five years , and begat Met\n",
      " ; for God took him . And Methuselah lived an hundred eighty and seven years , \n",
      " , and begat Lamech . And Methuselah lived after he begat Lamech seven hundred \n",
      "nd nine yea and he died . And Lamech lived an hundred eighty and two years , an\n",
      "ch the LORD hath cursed . And Lamech lived after he begat Noah five hundred nin\n",
      "naan shall be his servant . And Noah lived after the flood three hundred and fi\n",
      "xad two years after the flo And Shem lived after he begat Arphaxad five hundred\n",
      "at sons and daughters . And Arphaxad lived five and thirty years , and begat Sa\n",
      "ars , and begat Salah : And Arphaxad lived after he begat Salah four hundred an\n",
      "begat sons and daughters . And Salah lived thirty years , and begat Eber : And \n",
      "y years , and begat Eber : And Salah lived after he begat Eber four hundred and\n",
      " begat sons and daughters . And Eber lived four and thirty years , and begat Pe\n",
      "y years , and begat Peleg : And Eber lived after he begat Peleg four hundred an\n"
     ]
    }
   ],
   "source": [
    "text3.concordance(\"lived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A concordance permits us to see words in context. For example, we saw that monstrous occurred in contexts such as the ___ pictures and a ___ size . What other words appear in a similar range of contexts? We can find out by appending the term similar to the name of the text in question, then inserting the relevant word in parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n"
     ]
    }
   ],
   "source": [
    "text1.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very so exceedingly heartily a as good great extremely remarkably\n",
      "sweet vast amazingly\n"
     ]
    }
   ],
   "source": [
    "text2.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got different results for different texts. Austen uses this word quite differently from Melville; for her, monstrous has positive connotations, and sometimes functions as an intensifier like the word very."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term common_contexts allows us to examine just the contexts that are shared by two or more words, such as monstrous and very."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_pretty am_glad a_lucky is_pretty be_glad\n"
     ]
    }
   ],
   "source": [
    "text2.common_contexts([\"monstrous\", \"very\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_pretty\n"
     ]
    }
   ],
   "source": [
    "text2.common_contexts([\"monstrous\", \"sweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the_pictures\n"
     ]
    }
   ],
   "source": [
    "text1.common_contexts([\"monstrous\", \"true\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also determine the location of a word in the text: how many words from the beginning it appears. This positional information can be displayed using a dispersion plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, just for fun, let's try generating some random text in the various styles we have just seen. To do this, we type the name of the text followed by the term generate. (We need to include the parentheses, but there's nothing that goes between them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building ngram index...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laid by her , and said unto Cain , Where art thou , and said , Go to ,\n",
      "I will not do it for ten ' s sons ; we dreamed each man according to\n",
      "their generatio the firstborn said unto Laban , Because I said , Nay ,\n",
      "but Sarah shall her name be . , duke Elah , duke Shobal , and Akan .\n",
      "and looked upon my affliction . Bashemath Ishmael ' s blood , but Isra\n",
      "for as a prince hast thou found of all the cattle in the valley , and\n",
      "the wo The\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"laid by her , and said unto Cain , Where art thou , and said , Go to ,\\nI will not do it for ten ' s sons ; we dreamed each man according to\\ntheir generatio the firstborn said unto Laban , Because I said , Nay ,\\nbut Sarah shall her name be . , duke Elah , duke Shobal , and Akan .\\nand looked upon my affliction . Bashemath Ishmael ' s blood , but Isra\\nfor as a prince hast thou found of all the cattle in the valley , and\\nthe wo The\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by finding out the length of a text from start to finish, in terms of the words and punctuation symbols that appear. We use the term len to get the length of something, which we'll apply here to the book of Genesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44764"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary of a text is just the set of tokens that it uses, since in a set, all duplicates are collapsed together. In Python we can obtain the vocabulary items of text3 with the command: set(text3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ',)',\n",
       " '.',\n",
       " '.)',\n",
       " ':',\n",
       " ';',\n",
       " ';)',\n",
       " '?',\n",
       " '?)',\n",
       " 'A',\n",
       " 'Abel',\n",
       " 'Abelmizraim',\n",
       " 'Abidah',\n",
       " 'Abide',\n",
       " 'Abimael',\n",
       " 'Abimelech',\n",
       " 'Abr',\n",
       " 'Abrah',\n",
       " 'Abraham',\n",
       " 'Abram',\n",
       " 'Accad',\n",
       " 'Achbor',\n",
       " 'Adah',\n",
       " 'Adam',\n",
       " 'Adbeel',\n",
       " 'Admah',\n",
       " 'Adullamite',\n",
       " 'After',\n",
       " 'Aholibamah',\n",
       " 'Ahuzzath',\n",
       " 'Ajah',\n",
       " 'Akan',\n",
       " 'All',\n",
       " 'Allonbachuth',\n",
       " 'Almighty',\n",
       " 'Almodad',\n",
       " 'Also',\n",
       " 'Alvah',\n",
       " 'Alvan',\n",
       " 'Am',\n",
       " 'Amal',\n",
       " 'Amalek',\n",
       " 'Amalekites',\n",
       " 'Ammon',\n",
       " 'Amorite',\n",
       " 'Amorites',\n",
       " 'Amraphel',\n",
       " 'An',\n",
       " 'Anah',\n",
       " 'Anamim',\n",
       " 'And',\n",
       " 'Aner',\n",
       " 'Angel',\n",
       " 'Appoint',\n",
       " 'Aram',\n",
       " 'Aran',\n",
       " 'Ararat',\n",
       " 'Arbah',\n",
       " 'Ard',\n",
       " 'Are',\n",
       " 'Areli',\n",
       " 'Arioch',\n",
       " 'Arise',\n",
       " 'Arkite',\n",
       " 'Arodi',\n",
       " 'Arphaxad',\n",
       " 'Art',\n",
       " 'Arvadite',\n",
       " 'As',\n",
       " 'Asenath',\n",
       " 'Ashbel',\n",
       " 'Asher',\n",
       " 'Ashkenaz',\n",
       " 'Ashteroth',\n",
       " 'Ask',\n",
       " 'Asshur',\n",
       " 'Asshurim',\n",
       " 'Assyr',\n",
       " 'Assyria',\n",
       " 'At',\n",
       " 'Atad',\n",
       " 'Avith',\n",
       " 'Baalhanan',\n",
       " 'Babel',\n",
       " 'Bashemath',\n",
       " 'Be',\n",
       " 'Because',\n",
       " 'Becher',\n",
       " 'Bedad',\n",
       " 'Beeri',\n",
       " 'Beerlahairoi',\n",
       " 'Beersheba',\n",
       " 'Behold',\n",
       " 'Bela',\n",
       " 'Belah',\n",
       " 'Benam',\n",
       " 'Benjamin',\n",
       " 'Beno',\n",
       " 'Beor',\n",
       " 'Bera',\n",
       " 'Bered',\n",
       " 'Beriah',\n",
       " 'Bethel',\n",
       " 'Bethlehem',\n",
       " 'Bethuel',\n",
       " 'Beware',\n",
       " 'Bilhah',\n",
       " 'Bilhan',\n",
       " 'Binding',\n",
       " 'Birsha',\n",
       " 'Bless',\n",
       " 'Blessed',\n",
       " 'Both',\n",
       " 'Bow',\n",
       " 'Bozrah',\n",
       " 'Bring',\n",
       " 'But',\n",
       " 'Buz',\n",
       " 'By',\n",
       " 'Cain',\n",
       " 'Cainan',\n",
       " 'Calah',\n",
       " 'Calneh',\n",
       " 'Can',\n",
       " 'Cana',\n",
       " 'Canaan',\n",
       " 'Canaanite',\n",
       " 'Canaanites',\n",
       " 'Canaanitish',\n",
       " 'Caphtorim',\n",
       " 'Carmi',\n",
       " 'Casluhim',\n",
       " 'Cast',\n",
       " 'Cause',\n",
       " 'Chaldees',\n",
       " 'Chedorlaomer',\n",
       " 'Cheran',\n",
       " 'Cherubims',\n",
       " 'Chesed',\n",
       " 'Chezib',\n",
       " 'Come',\n",
       " 'Cursed',\n",
       " 'Cush',\n",
       " 'Damascus',\n",
       " 'Dan',\n",
       " 'Day',\n",
       " 'Deborah',\n",
       " 'Dedan',\n",
       " 'Deliver',\n",
       " 'Diklah',\n",
       " 'Din',\n",
       " 'Dinah',\n",
       " 'Dinhabah',\n",
       " 'Discern',\n",
       " 'Dishan',\n",
       " 'Dishon',\n",
       " 'Do',\n",
       " 'Dodanim',\n",
       " 'Dothan',\n",
       " 'Drink',\n",
       " 'Duke',\n",
       " 'Dumah',\n",
       " 'Earth',\n",
       " 'Ebal',\n",
       " 'Eber',\n",
       " 'Edar',\n",
       " 'Eden',\n",
       " 'Edom',\n",
       " 'Edomites',\n",
       " 'Egy',\n",
       " 'Egypt',\n",
       " 'Egyptia',\n",
       " 'Egyptian',\n",
       " 'Egyptians',\n",
       " 'Ehi',\n",
       " 'Elah',\n",
       " 'Elam',\n",
       " 'Elbethel',\n",
       " 'Eldaah',\n",
       " 'EleloheIsrael',\n",
       " 'Eliezer',\n",
       " 'Eliphaz',\n",
       " 'Elishah',\n",
       " 'Ellasar',\n",
       " 'Elon',\n",
       " 'Elparan',\n",
       " 'Emins',\n",
       " 'En',\n",
       " 'Enmishpat',\n",
       " 'Eno',\n",
       " 'Enoch',\n",
       " 'Enos',\n",
       " 'Ephah',\n",
       " 'Epher',\n",
       " 'Ephra',\n",
       " 'Ephraim',\n",
       " 'Ephrath',\n",
       " 'Ephron',\n",
       " 'Er',\n",
       " 'Erech',\n",
       " 'Eri',\n",
       " 'Es',\n",
       " 'Esau',\n",
       " 'Escape',\n",
       " 'Esek',\n",
       " 'Eshban',\n",
       " 'Eshcol',\n",
       " 'Ethiopia',\n",
       " 'Euphrat',\n",
       " 'Euphrates',\n",
       " 'Eve',\n",
       " 'Even',\n",
       " 'Every',\n",
       " 'Except',\n",
       " 'Ezbon',\n",
       " 'Ezer',\n",
       " 'Fear',\n",
       " 'Feed',\n",
       " 'Fifteen',\n",
       " 'Fill',\n",
       " 'For',\n",
       " 'Forasmuch',\n",
       " 'Forgive',\n",
       " 'From',\n",
       " 'Fulfil',\n",
       " 'G',\n",
       " 'Gad',\n",
       " 'Gaham',\n",
       " 'Galeed',\n",
       " 'Gatam',\n",
       " 'Gather',\n",
       " 'Gaza',\n",
       " 'Gentiles',\n",
       " 'Gera',\n",
       " 'Gerar',\n",
       " 'Gershon',\n",
       " 'Get',\n",
       " 'Gether',\n",
       " 'Gihon',\n",
       " 'Gilead',\n",
       " 'Girgashites',\n",
       " 'Girgasite',\n",
       " 'Give',\n",
       " 'Go',\n",
       " 'God',\n",
       " 'Gomer',\n",
       " 'Gomorrah',\n",
       " 'Goshen',\n",
       " 'Guni',\n",
       " 'Hadad',\n",
       " 'Hadar',\n",
       " 'Hadoram',\n",
       " 'Hagar',\n",
       " 'Haggi',\n",
       " 'Hai',\n",
       " 'Ham',\n",
       " 'Hamathite',\n",
       " 'Hamor',\n",
       " 'Hamul',\n",
       " 'Hanoch',\n",
       " 'Happy',\n",
       " 'Haran',\n",
       " 'Hast',\n",
       " 'Haste',\n",
       " 'Have',\n",
       " 'Havilah',\n",
       " 'Hazarmaveth',\n",
       " 'Hazezontamar',\n",
       " 'Hazo',\n",
       " 'He',\n",
       " 'Hear',\n",
       " 'Heaven',\n",
       " 'Heber',\n",
       " 'Hebrew',\n",
       " 'Hebrews',\n",
       " 'Hebron',\n",
       " 'Hemam',\n",
       " 'Hemdan',\n",
       " 'Here',\n",
       " 'Hereby',\n",
       " 'Heth',\n",
       " 'Hezron',\n",
       " 'Hiddekel',\n",
       " 'Hinder',\n",
       " 'Hirah',\n",
       " 'His',\n",
       " 'Hitti',\n",
       " 'Hittite',\n",
       " 'Hittites',\n",
       " 'Hivite',\n",
       " 'Hobah',\n",
       " 'Hori',\n",
       " 'Horite',\n",
       " 'Horites',\n",
       " 'How',\n",
       " 'Hul',\n",
       " 'Huppim',\n",
       " 'Husham',\n",
       " 'Hushim',\n",
       " 'Huz',\n",
       " 'I',\n",
       " 'If',\n",
       " 'In',\n",
       " 'Irad',\n",
       " 'Iram',\n",
       " 'Is',\n",
       " 'Isa',\n",
       " 'Isaac',\n",
       " 'Iscah',\n",
       " 'Ishbak',\n",
       " 'Ishmael',\n",
       " 'Ishmeelites',\n",
       " 'Ishuah',\n",
       " 'Isra',\n",
       " 'Israel',\n",
       " 'Issachar',\n",
       " 'Isui',\n",
       " 'It',\n",
       " 'Ithran',\n",
       " 'Jaalam',\n",
       " 'Jabal',\n",
       " 'Jabbok',\n",
       " 'Jac',\n",
       " 'Jachin',\n",
       " 'Jacob',\n",
       " 'Jahleel',\n",
       " 'Jahzeel',\n",
       " 'Jamin',\n",
       " 'Japhe',\n",
       " 'Japheth',\n",
       " 'Jared',\n",
       " 'Javan',\n",
       " 'Jebusite',\n",
       " 'Jebusites',\n",
       " 'Jegarsahadutha',\n",
       " 'Jehovahjireh',\n",
       " 'Jemuel',\n",
       " 'Jerah',\n",
       " 'Jetheth',\n",
       " 'Jetur',\n",
       " 'Jeush',\n",
       " 'Jezer',\n",
       " 'Jidlaph',\n",
       " 'Jimnah',\n",
       " 'Job',\n",
       " 'Jobab',\n",
       " 'Jokshan',\n",
       " 'Joktan',\n",
       " 'Jordan',\n",
       " 'Joseph',\n",
       " 'Jubal',\n",
       " 'Judah',\n",
       " 'Judge',\n",
       " 'Judith',\n",
       " 'Kadesh',\n",
       " 'Kadmonites',\n",
       " 'Karnaim',\n",
       " 'Kedar',\n",
       " 'Kedemah',\n",
       " 'Kemuel',\n",
       " 'Kenaz',\n",
       " 'Kenites',\n",
       " 'Kenizzites',\n",
       " 'Keturah',\n",
       " 'Kiriathaim',\n",
       " 'Kirjatharba',\n",
       " 'Kittim',\n",
       " 'Know',\n",
       " 'Kohath',\n",
       " 'Kor',\n",
       " 'Korah',\n",
       " 'LO',\n",
       " 'LORD',\n",
       " 'Laban',\n",
       " 'Lahairoi',\n",
       " 'Lamech',\n",
       " 'Lasha',\n",
       " 'Lay',\n",
       " 'Leah',\n",
       " 'Lehabim',\n",
       " 'Lest',\n",
       " 'Let',\n",
       " 'Letushim',\n",
       " 'Leummim',\n",
       " 'Levi',\n",
       " 'Lie',\n",
       " 'Lift',\n",
       " 'Lo',\n",
       " 'Look',\n",
       " 'Lot',\n",
       " 'Lotan',\n",
       " 'Lud',\n",
       " 'Ludim',\n",
       " 'Luz',\n",
       " 'Maachah',\n",
       " 'Machir',\n",
       " 'Machpelah',\n",
       " 'Madai',\n",
       " 'Magdiel',\n",
       " 'Magog',\n",
       " 'Mahalaleel',\n",
       " 'Mahalath',\n",
       " 'Mahanaim',\n",
       " 'Make',\n",
       " 'Malchiel',\n",
       " 'Male',\n",
       " 'Mam',\n",
       " 'Mamre',\n",
       " 'Man',\n",
       " 'Manahath',\n",
       " 'Manass',\n",
       " 'Manasseh',\n",
       " 'Mash',\n",
       " 'Masrekah',\n",
       " 'Massa',\n",
       " 'Matred',\n",
       " 'Me',\n",
       " 'Medan',\n",
       " 'Mehetabel',\n",
       " 'Mehujael',\n",
       " 'Melchizedek',\n",
       " 'Merari',\n",
       " 'Mesha',\n",
       " 'Meshech',\n",
       " 'Mesopotamia',\n",
       " 'Methusa',\n",
       " 'Methusael',\n",
       " 'Methuselah',\n",
       " 'Mezahab',\n",
       " 'Mibsam',\n",
       " 'Mibzar',\n",
       " 'Midian',\n",
       " 'Midianites',\n",
       " 'Milcah',\n",
       " 'Mishma',\n",
       " 'Mizpah',\n",
       " 'Mizraim',\n",
       " 'Mizz',\n",
       " 'Moab',\n",
       " 'Moabites',\n",
       " 'Moreh',\n",
       " 'Moreover',\n",
       " 'Moriah',\n",
       " 'Muppim',\n",
       " 'My',\n",
       " 'Naamah',\n",
       " 'Naaman',\n",
       " 'Nahath',\n",
       " 'Nahor',\n",
       " 'Naphish',\n",
       " 'Naphtali',\n",
       " 'Naphtuhim',\n",
       " 'Nay',\n",
       " 'Nebajoth',\n",
       " 'Neither',\n",
       " 'Night',\n",
       " 'Nimrod',\n",
       " 'Nineveh',\n",
       " 'Noah',\n",
       " 'Nod',\n",
       " 'Not',\n",
       " 'Now',\n",
       " 'O',\n",
       " 'Obal',\n",
       " 'Of',\n",
       " 'Oh',\n",
       " 'Ohad',\n",
       " 'Omar',\n",
       " 'On',\n",
       " 'Onam',\n",
       " 'Onan',\n",
       " 'Only',\n",
       " 'Ophir',\n",
       " 'Our',\n",
       " 'Out',\n",
       " 'Padan',\n",
       " 'Padanaram',\n",
       " 'Paran',\n",
       " 'Pass',\n",
       " 'Pathrusim',\n",
       " 'Pau',\n",
       " 'Peace',\n",
       " 'Peleg',\n",
       " 'Peniel',\n",
       " 'Penuel',\n",
       " 'Peradventure',\n",
       " 'Perizzit',\n",
       " 'Perizzite',\n",
       " 'Perizzites',\n",
       " 'Phallu',\n",
       " 'Phara',\n",
       " 'Pharaoh',\n",
       " 'Pharez',\n",
       " 'Phichol',\n",
       " 'Philistim',\n",
       " 'Philistines',\n",
       " 'Phut',\n",
       " 'Phuvah',\n",
       " 'Pildash',\n",
       " 'Pinon',\n",
       " 'Pison',\n",
       " 'Potiphar',\n",
       " 'Potipherah',\n",
       " 'Put',\n",
       " 'Raamah',\n",
       " 'Rachel',\n",
       " 'Rameses',\n",
       " 'Rebek',\n",
       " 'Rebekah',\n",
       " 'Rehoboth',\n",
       " 'Remain',\n",
       " 'Rephaims',\n",
       " 'Resen',\n",
       " 'Return',\n",
       " 'Reu',\n",
       " 'Reub',\n",
       " 'Reuben',\n",
       " 'Reuel',\n",
       " 'Reumah',\n",
       " 'Riphath',\n",
       " 'Rosh',\n",
       " 'Sabtah',\n",
       " 'Sabtech',\n",
       " 'Said',\n",
       " 'Salah',\n",
       " 'Salem',\n",
       " 'Samlah',\n",
       " 'Sarah',\n",
       " 'Sarai',\n",
       " 'Saul',\n",
       " 'Save',\n",
       " 'Say',\n",
       " 'Se',\n",
       " 'Seba',\n",
       " 'See',\n",
       " 'Seeing',\n",
       " 'Seir',\n",
       " 'Sell',\n",
       " 'Send',\n",
       " 'Sephar',\n",
       " 'Serah',\n",
       " 'Sered',\n",
       " 'Serug',\n",
       " 'Set',\n",
       " 'Seth',\n",
       " 'Shalem',\n",
       " 'Shall',\n",
       " 'Shalt',\n",
       " 'Shammah',\n",
       " 'Shaul',\n",
       " 'Shaveh',\n",
       " 'She',\n",
       " 'Sheba',\n",
       " 'Shebah',\n",
       " 'Shechem',\n",
       " 'Shed',\n",
       " 'Shel',\n",
       " 'Shelah',\n",
       " 'Sheleph',\n",
       " 'Shem',\n",
       " 'Shemeber',\n",
       " 'Shepho',\n",
       " 'Shillem',\n",
       " 'Shiloh',\n",
       " 'Shimron',\n",
       " 'Shinab',\n",
       " 'Shinar',\n",
       " 'Shobal',\n",
       " 'Should',\n",
       " 'Shuah',\n",
       " 'Shuni',\n",
       " 'Shur',\n",
       " 'Sichem',\n",
       " 'Siddim',\n",
       " 'Sidon',\n",
       " 'Simeon',\n",
       " 'Sinite',\n",
       " 'Sitnah',\n",
       " 'Slay',\n",
       " 'So',\n",
       " 'Sod',\n",
       " 'Sodom',\n",
       " 'Sojourn',\n",
       " 'Some',\n",
       " 'Spake',\n",
       " 'Speak',\n",
       " 'Spirit',\n",
       " 'Stand',\n",
       " 'Succoth',\n",
       " 'Surely',\n",
       " 'Swear',\n",
       " 'Syrian',\n",
       " 'Take',\n",
       " 'Tamar',\n",
       " 'Tarshish',\n",
       " 'Tebah',\n",
       " 'Tell',\n",
       " 'Tema',\n",
       " 'Teman',\n",
       " 'Temani',\n",
       " 'Terah',\n",
       " 'Thahash',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Then',\n",
       " 'There',\n",
       " 'Therefore',\n",
       " 'These',\n",
       " 'They',\n",
       " 'Thirty',\n",
       " 'This',\n",
       " 'Thorns',\n",
       " 'Thou',\n",
       " 'Thus',\n",
       " 'Thy',\n",
       " 'Tidal',\n",
       " 'Timna',\n",
       " 'Timnah',\n",
       " 'Timnath',\n",
       " 'Tiras',\n",
       " 'To',\n",
       " 'Togarmah',\n",
       " 'Tola',\n",
       " 'Tubal',\n",
       " 'Tubalcain',\n",
       " 'Twelve',\n",
       " 'Two',\n",
       " 'Unstable',\n",
       " 'Until',\n",
       " 'Unto',\n",
       " 'Up',\n",
       " 'Upon',\n",
       " 'Ur',\n",
       " 'Uz',\n",
       " 'Uzal',\n",
       " 'We',\n",
       " 'What',\n",
       " 'When',\n",
       " 'Whence',\n",
       " 'Where',\n",
       " 'Whereas',\n",
       " 'Wherefore',\n",
       " 'Which',\n",
       " 'While',\n",
       " 'Who',\n",
       " 'Whose',\n",
       " 'Whoso',\n",
       " 'Why',\n",
       " 'Wilt',\n",
       " 'With',\n",
       " 'Woman',\n",
       " 'Ye',\n",
       " 'Yea',\n",
       " 'Yet',\n",
       " 'Zaavan',\n",
       " 'Zaphnathpaaneah',\n",
       " 'Zar',\n",
       " 'Zarah',\n",
       " 'Zeboiim',\n",
       " 'Zeboim',\n",
       " 'Zebul',\n",
       " 'Zebulun',\n",
       " 'Zemarite',\n",
       " 'Zepho',\n",
       " 'Zerah',\n",
       " 'Zibeon',\n",
       " 'Zidon',\n",
       " 'Zillah',\n",
       " 'Zilpah',\n",
       " 'Zimran',\n",
       " 'Ziphion',\n",
       " 'Zo',\n",
       " 'Zoar',\n",
       " 'Zohar',\n",
       " 'Zuzims',\n",
       " 'a',\n",
       " 'abated',\n",
       " 'abide',\n",
       " 'able',\n",
       " 'abode',\n",
       " 'abomination',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absent',\n",
       " 'abundantly',\n",
       " 'accept',\n",
       " 'accepted',\n",
       " 'according',\n",
       " 'acknowledged',\n",
       " 'activity',\n",
       " 'add',\n",
       " 'adder',\n",
       " 'afar',\n",
       " 'afflict',\n",
       " 'affliction',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'aga',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'aileth',\n",
       " 'air',\n",
       " 'al',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'almon',\n",
       " 'alo',\n",
       " 'alone',\n",
       " 'aloud',\n",
       " 'also',\n",
       " 'altar',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'angel',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'anguish',\n",
       " 'anointedst',\n",
       " 'anoth',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'any',\n",
       " 'anything',\n",
       " 'appe',\n",
       " 'appear',\n",
       " 'appeared',\n",
       " 'appease',\n",
       " 'appoint',\n",
       " 'appointed',\n",
       " 'aprons',\n",
       " 'archer',\n",
       " 'archers',\n",
       " 'are',\n",
       " 'arise',\n",
       " 'ark',\n",
       " 'armed',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arose',\n",
       " 'arrayed',\n",
       " 'art',\n",
       " 'artificer',\n",
       " 'as',\n",
       " 'ascending',\n",
       " 'ash',\n",
       " 'ashamed',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asketh',\n",
       " 'ass',\n",
       " 'assembly',\n",
       " 'asses',\n",
       " 'assigned',\n",
       " 'asswaged',\n",
       " 'at',\n",
       " 'attained',\n",
       " 'audience',\n",
       " 'avenged',\n",
       " 'aw',\n",
       " 'awaked',\n",
       " 'away',\n",
       " 'awoke',\n",
       " 'back',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'bade',\n",
       " 'badest',\n",
       " 'badne',\n",
       " 'bak',\n",
       " 'bake',\n",
       " 'bakemeats',\n",
       " 'baker',\n",
       " 'bakers',\n",
       " 'balm',\n",
       " 'bands',\n",
       " 'bank',\n",
       " 'bare',\n",
       " 'barr',\n",
       " 'barren',\n",
       " 'basket',\n",
       " 'baskets',\n",
       " 'battle',\n",
       " 'bdellium',\n",
       " 'be',\n",
       " 'bear',\n",
       " 'beari',\n",
       " 'bearing',\n",
       " 'beast',\n",
       " 'beasts',\n",
       " 'beautiful',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'befall',\n",
       " 'befell',\n",
       " 'before',\n",
       " 'began',\n",
       " 'begat',\n",
       " 'beget',\n",
       " 'begettest',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begotten',\n",
       " 'beguiled',\n",
       " 'beheld',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'being',\n",
       " 'believed',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'beneath',\n",
       " 'bereaved',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'besought',\n",
       " 'best',\n",
       " 'betimes',\n",
       " 'better',\n",
       " 'between',\n",
       " 'betwixt',\n",
       " 'beyond',\n",
       " 'binding',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birthday',\n",
       " 'birthright',\n",
       " 'biteth',\n",
       " 'bitter',\n",
       " 'blame',\n",
       " 'blameless',\n",
       " 'blasted',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blesseth',\n",
       " 'blessi',\n",
       " 'blessing',\n",
       " 'blessings',\n",
       " 'blindness',\n",
       " 'blood',\n",
       " 'blossoms',\n",
       " 'bodies',\n",
       " 'boldly',\n",
       " 'bondman',\n",
       " 'bondmen',\n",
       " 'bondwoman',\n",
       " 'bone',\n",
       " 'bones',\n",
       " 'book',\n",
       " 'booths',\n",
       " 'border',\n",
       " 'borders',\n",
       " 'born',\n",
       " 'bosom',\n",
       " 'both',\n",
       " 'bottle',\n",
       " 'bou',\n",
       " 'boug',\n",
       " 'bough',\n",
       " 'bought',\n",
       " 'bound',\n",
       " 'bow',\n",
       " 'bowed',\n",
       " 'bowels',\n",
       " 'bowing',\n",
       " 'boys',\n",
       " 'bracelets',\n",
       " 'branches',\n",
       " 'brass',\n",
       " 'bre',\n",
       " 'breach',\n",
       " 'bread',\n",
       " 'breadth',\n",
       " 'break',\n",
       " 'breaketh',\n",
       " 'breaking',\n",
       " 'breasts',\n",
       " 'breath',\n",
       " 'breathed',\n",
       " 'breed',\n",
       " 'brethren',\n",
       " 'brick',\n",
       " 'brimstone',\n",
       " 'bring',\n",
       " 'brink',\n",
       " 'broken',\n",
       " 'brook',\n",
       " 'broth',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'bruise',\n",
       " 'budded',\n",
       " 'build',\n",
       " 'builded',\n",
       " 'built',\n",
       " 'bulls',\n",
       " 'bundle',\n",
       " 'bundles',\n",
       " 'burdens',\n",
       " 'buried',\n",
       " 'burn',\n",
       " 'burning',\n",
       " 'burnt',\n",
       " 'bury',\n",
       " 'buryingplace',\n",
       " 'business',\n",
       " 'but',\n",
       " 'butler',\n",
       " 'butlers',\n",
       " 'butlership',\n",
       " 'butter',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'cakes',\n",
       " 'calf',\n",
       " 'call',\n",
       " 'called',\n",
       " 'came',\n",
       " 'camel',\n",
       " 'camels',\n",
       " 'camest',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'canst',\n",
       " 'captain',\n",
       " 'captive',\n",
       " 'captives',\n",
       " 'carcases',\n",
       " 'carried',\n",
       " 'carry',\n",
       " 'cast',\n",
       " 'castles',\n",
       " 'catt',\n",
       " 'cattle',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'cave',\n",
       " 'cease',\n",
       " 'ceased',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chain',\n",
       " 'chamber',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'chariot',\n",
       " 'chariots',\n",
       " 'chesnut',\n",
       " 'chi',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childless',\n",
       " 'childr',\n",
       " 'children',\n",
       " 'chode',\n",
       " 'choice',\n",
       " 'chose',\n",
       " 'circumcis',\n",
       " 'circumcise',\n",
       " 'circumcised',\n",
       " 'citi',\n",
       " 'cities',\n",
       " 'city',\n",
       " 'clave',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'cleave',\n",
       " 'clo',\n",
       " 'closed',\n",
       " 'clothed',\n",
       " 'clothes',\n",
       " 'cloud',\n",
       " 'clusters',\n",
       " 'co',\n",
       " 'coat',\n",
       " 'coats',\n",
       " 'coffin',\n",
       " 'cold',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2789"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By wrapping sorted() around the Python expression set(text3), we obtain a sorted list of vocabulary items, beginning with various punctuation symbols and continuing with words starting with A. All capitalized words precede lowercase words. We discover the size of the vocabulary indirectly, by asking for the number of items in the set, and again we can use len to obtain this number. Although it has 44,764 tokens, this book has only 2,789 distinct words, or \"word types.\" A word type is the form or spelling of the word independently of its specific occurrences in a text — that is, the word considered as a unique item of vocabulary. Our count of 2,789 items will include punctuation symbols, so we will generally call these unique items types instead of word types.\n",
    "\n",
    "Now, let's calculate a measure of the lexical richness of the text. The next example shows us that the number of distinct words is just 6% of the total number of words, or equivalently that each word is used 16 times on average (remember if you're using Python 2, to start with from __future__ import division)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text3)) / len(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's focus on particular words. We can count how often a word occurs in a text, and compute what percentage of the text is taken up by a specific word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3.count(\"smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.457973123627309"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * text4.count('a') / len(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3.count(\"lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text5.count(\"lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5640968673628082"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * text5.count('lol') / len(text5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that text3: The Book of Genesis does not contain word \"lol\" at all. text5: Chat Corpus has 704 of words \"lol\", which is 1.56% of the whole text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next example shows how to define two new functions, lexical_diversity() and  percentage():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "     return len(set(text)) / len(text)\n",
    "    \n",
    "def percentage(count, total):\n",
    "     return 100 * count / total    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13477005109975562"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.457973123627309"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage(text4.count('a'), len(text4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Go to http://www.gutenberg.org/wiki/Children%27s_Instructional_Books_(Bookshelf), and obtain three texts (of different grade levels) from the “Graded Readers” section. Report the lexical diversity score of each. Explain whether the result was surprising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The Project Gutenberg EBook of McGuffey's First Eclectic Reader, Revised\\n\", 'Edition, by William Holmes McGuffey\\n']\n"
     ]
    }
   ],
   "source": [
    "f1=open(\"HW/books/14640.txt\")\n",
    "line1 =f1.readlines()[0:2]\n",
    "print (line1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The Project Gutenberg EBook of McGuffey's Third Eclectic Reader\\n\", 'by William Holmes McGuffey\\n']\n"
     ]
    }
   ],
   "source": [
    "f2=open(\"HW/books/14766.txt\", \"r\")\n",
    "book2 =f2.readlines()[0:2]\n",
    "print (book2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The Project Gutenberg EBook of McGuffey's Sixth Eclectic Reader\\n\", 'by William Holmes McGuffey\\n']\n"
     ]
    }
   ],
   "source": [
    "f3=open(\"HW/books/16751.txt\", \"r\")\n",
    "book3 =f3.readlines()[0:2]\n",
    "print (book3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=open(\"HW/books/14640.txt\")\n",
    "book1 =f1.read()\n",
    "tokens1 = nltk.word_tokenize(book1)\n",
    "txt1 = nltk.Text(tokens1)\n",
    "lexical_diversity1 = lexical_diversity(txt1)\n",
    "vocab1 = len(set(txt1))\n",
    "len1 = len(txt1)\n",
    "name1 = 'The Project Gutenberg EBook of McGuffeys First Eclectic Reader'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2=open(\"HW/books/14766.txt\", \"r\")\n",
    "book2 =f2.read()\n",
    "tokens2 = nltk.word_tokenize(book2)\n",
    "txt2 = nltk.Text(tokens2)\n",
    "lexical_diversity2 = lexical_diversity(txt2)\n",
    "vocab2 = len(set(txt2))\n",
    "len2 = len(txt2)\n",
    "name2 = 'The Project Gutenberg EBook of McGuffeys Third Eclectic Reader'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3=open(\"HW/books/16751.txt\", \"r\")\n",
    "book3 =f3.read()\n",
    "tokens3 = nltk.word_tokenize(book3)\n",
    "txt3 = nltk.Text(tokens3)\n",
    "lexical_diversity3 = lexical_diversity(txt3)\n",
    "vocab3 = len(set(txt3))\n",
    "len3 = len(txt3)\n",
    "name3 = 'The Project Gutenberg EBook of McGuffeys Sixth Eclectic Reader'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book                                                              Lexical diversity    Vocabulary size    Text length\n",
      "--------------------------------------------------------------  -------------------  -----------------  -------------\n",
      "The Project Gutenberg EBook of McGuffeys First Eclectic Reader             0.167108               2147          12848\n",
      "The Project Gutenberg EBook of McGuffeys Third Eclectic Reader             0.124148               4715          37979\n",
      "The Project Gutenberg EBook of McGuffeys Sixth Eclectic Reader             0.10088               17260         171094\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(tabulate([[name1, lexical_diversity1,vocab1, len1], [name2, lexical_diversity2,vocab2,len2], [name3, lexical_diversity3,vocab3,len3]], headers=['Book','Lexical diversity', 'Vocabulary size', 'Text length']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Lexical diversity rates for young kids and older readers are 16% and 10% respectively. This result is surprising. For this two categories we expected to see smaller lexical diversity rate for small kids or higher for older readers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Also compare the vocabulary size of the same three texts. Explain whether the result was surprising. \n",
    "Vocabulary size for small kids is 2147, and older readers is 17260. This looks logical, sinse older readers should have stronger vocabulary than smaller kids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write a paragraph arguing whether vocabulary size and lexical diversity in combination could be a better measure of text difficulty (or reading level) than either measure is by itself.\n",
    "Vocabulary size and lexical diversity in combination will be a better measure of text difficulty (or reading level). Sinse lexical diversity and vocabulary size are sensetive to the text length, it is better to use them as a measure of text difficulty in combination, sinse by itself they do not represent the real picture like we saw in the example with The Project Gutenberg EBook of McGuffeys. With increasing of text length you will get decreasing of Lexical diversity and the main reason, I think, may be function words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
