{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW #4\n",
    "\n",
    "#### Student name: Olha Tanyuk\n",
    "###### 1.\tRun one of the part-of-speech (POS) taggers available in Python.\n",
    "\n",
    "a.\tFind the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.\n",
    "\n",
    "b.\tFind the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. Explain your conjecture as to why the tagger might have been less than perfect with this sentence.\n",
    "\n",
    "###### 2.\tRun a different POS tagger in Python. Process the same two sentences from question 1.\n",
    "\n",
    "a.\tDoes it produce the same or different output?\n",
    "\n",
    "b.\tExplain any differences as best you can.\n",
    "\n",
    "###### 3.\tIn a news article from this weekâ€™s news, find a random sentence of at least 10 words.\n",
    "\n",
    "a.\tLooking at the Penn tag set, manually POS tag the sentence yourself.\n",
    "\n",
    "b.\tNow run the same sentences through both taggers that you implemented for questions 1 and 2. Did either of the taggers produce the same results as you had created manually?\n",
    "\n",
    "c.\tExplain any differences between the two taggers and your manual tagging as much as you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\otany\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\otany\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.corpus import brown\n",
    "from nltk import word_tokenize\n",
    "nltk.download('brown')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'building', 'of', 'the', 'British', 'Empire', 'may', 'be', 'said', 'to', 'have', 'begun', 'with', 'the', 'ascent', 'of', 'Queen', 'Elizabeth', 'to', 'the', 'throne', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('building', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('British', 'JJ'),\n",
       " ('Empire', 'NNP'),\n",
       " ('may', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('said', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('have', 'VB'),\n",
       " ('begun', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('ascent', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Queen', 'NNP'),\n",
       " ('Elizabeth', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('throne', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = word_tokenize(\"The building of the British Empire may be said to have begun with the ascent of Queen Elizabeth to the throne.\")\n",
    "print(text)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'swimming', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'), ('love', 'VBP'), ('swimming', 'VBG'), ('.', '.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_short = word_tokenize(\"I love swimming.\")\n",
    "print(text_short)\n",
    "nltk.pos_tag(text_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Swimming\" should be a noun in this case, not verb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('building', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('British', 'JJ'),\n",
       " ('Empire', 'NN-TL'),\n",
       " ('may', 'MD'),\n",
       " ('be', 'BE'),\n",
       " ('said', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('have', 'HV'),\n",
       " ('begun', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('ascent', None),\n",
       " ('of', 'IN'),\n",
       " ('Queen', 'NN-TL'),\n",
       " ('Elizabeth', 'NP'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'AT'),\n",
       " ('throne', None),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = UnigramTagger(brown.tagged_sents(categories='news'))\n",
    "tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the difference in tags, since Brown Corpus has 81 tags, and Penn Treebank pos tag from question (1) has just 45 tags. Overall output tagging for those two techniques looks the same, except UnigramTagger was not able to identify tag for \"throne\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PPSS'), ('love', 'VB'), ('swimming', 'VBG'), ('.', '.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(text_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UnigramTagger did the same mistake for \"swimming\", as pos tag did in Q1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Temperatures', 'dropped', 'by', 'the', 'dozens', 'after', 'a', 'cold', 'front', 'brought', 'some', 'storms', 'and', 'much', 'cooler', 'weather', 'to', 'Oklahoma', 'Thursday', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Temperatures', 'NNS'),\n",
       " ('dropped', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('dozens', 'NNS'),\n",
       " ('after', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('cold', 'JJ'),\n",
       " ('front', 'NN'),\n",
       " ('brought', 'VBD'),\n",
       " ('some', 'DT'),\n",
       " ('storms', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('much', 'JJ'),\n",
       " ('cooler', 'NN'),\n",
       " ('weather', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('Oklahoma', 'NNP'),\n",
       " ('Thursday', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = word_tokenize(\"Temperatures dropped by the dozens after a cold front brought some storms and much cooler weather to Oklahoma Thursday.\")\n",
    "print(text2)\n",
    "nltk.pos_tag(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Temperatures', None),\n",
       " ('dropped', 'VBD'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('dozens', 'NNS'),\n",
       " ('after', 'IN'),\n",
       " ('a', 'AT'),\n",
       " ('cold', 'JJ'),\n",
       " ('front', 'NN'),\n",
       " ('brought', 'VBD'),\n",
       " ('some', 'DTI'),\n",
       " ('storms', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('much', 'AP'),\n",
       " ('cooler', None),\n",
       " ('weather', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('Oklahoma', 'NP'),\n",
       " ('Thursday', 'NR'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram tagger was not able to identify tag for \"Temperatures\", \"cooler\". Probably because training set \"news\" were choose incorrectly. Pos_tag and Unigram clasified differently tag for \"much\": as adjective and post-determiner. I think both are correct depending what tag set you use. We were asked, using Penn tag set, manually POS tag the sentence yourself. My tags matches with pos_tag output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
